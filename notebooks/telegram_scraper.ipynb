{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb2e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Environment and dependencies ---\n",
    "from telethon.sync import TelegramClient\n",
    "from telethon.errors import FloodWaitError, RPCError\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "import aiofiles\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0236466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "api_id = os.getenv(\"TELEGRAM_API_ID\")\n",
    "api_hash = os.getenv(\"TELEGRAM_API_HASH\")\n",
    "phone = os.getenv(\"TELEGRAM_PHONE\")  # Optional: for first-time login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32121f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create handlers for logging to file and console\n",
    "if not os.path.exists('../logs'):\n",
    "    os.makedirs('../logs')\n",
    "\n",
    "# Create file and console handlers\n",
    "file_handler = logging.FileHandler('../logs/scrape.log')\n",
    "console_handler = logging.StreamHandler()\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "logger.handlers = []\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81f16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 19:39:26,462 - INFO - Scraping window: 2025-07-06T16:39:26.462491+00:00 to 2025-07-13T16:39:26.462491+00:00\n"
     ]
    }
   ],
   "source": [
    "DATA_LAKE_PATH = \"../data/raw/telegram_messages\"\n",
    "CHANNELS = [\"chemed123\", \"lobelia4cosmetics\", \"tikvahpharma\"]\n",
    "\n",
    "# Scraping date range (past 7 days)\n",
    "utc = pytz.UTC\n",
    "end_date = datetime.now(utc)\n",
    "start_date = end_date - timedelta(days=7)\n",
    "\n",
    "logger.info(f\"Scraping window STARTED AT: {start_date} UTC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13e1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_channel(client, channel, limit=500):\n",
    "    try:\n",
    "        logger.info(f\"Scraping from beginning for channel: {channel}\")\n",
    "        os.makedirs(DATA_LAKE_PATH, exist_ok=True)\n",
    "        entity = await client.get_entity(channel)\n",
    "\n",
    "        channel_path = os.path.join(DATA_LAKE_PATH, channel)\n",
    "        os.makedirs(channel_path, exist_ok=True)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        async for message in client.iter_messages(entity, limit=limit):\n",
    "            date_str = message.date.strftime(\"%Y-%m-%d\")\n",
    "            file_path = os.path.join(channel_path, f\"{date_str}.json\")\n",
    "\n",
    "            message_data = {\n",
    "                \"message_id\": message.id,\n",
    "                \"date\": message.date.isoformat(),\n",
    "                \"text\": message.text,\n",
    "                \"has_media\": bool(message.media),\n",
    "                \"media_type\": None,\n",
    "                \"media_path\": None\n",
    "            }\n",
    "\n",
    "            if message.photo:\n",
    "                media_path = os.path.join(channel_path, \"images\", f\"{message.id}.jpg\")\n",
    "                os.makedirs(os.path.dirname(media_path), exist_ok=True)\n",
    "                try:\n",
    "                    await client.download_media(message, media_path)\n",
    "                    message_data[\"media_type\"] = \"photo\"\n",
    "                    message_data[\"media_path\"] = media_path\n",
    "                    logger.info(f\"Downloaded image for message {message.id}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"X Failed to download image {message.id}: {str(e)}\")\n",
    "\n",
    "            async with aiofiles.open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                await f.write(json.dumps(message_data) + \"\\n\")\n",
    "\n",
    "            count += 1\n",
    "            if count >= limit:\n",
    "                logger.info(f\"----->Reached message limit of {limit} for {channel}\")\n",
    "                break\n",
    "\n",
    "            await asyncio.sleep(0.5)\n",
    "\n",
    "        logger.info(f\"=>> Finished scraping {count} messages from {channel}\")\n",
    "\n",
    "    except FloodWaitError as e:\n",
    "        logger.warning(f\"Rate limit: waiting {e.seconds} seconds for {channel}\")\n",
    "        await asyncio.sleep(e.seconds)\n",
    "    except RPCError as e:\n",
    "        logger.error(f\"Telegram API error for {channel}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error for {channel}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a740c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scrape_channel() takes from 2 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m30\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Trigger the scraping\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_scraping()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mrun_scraping\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m client.sign_in(phone, code)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m CHANNELS:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mscrape_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSleeping 30 seconds before next channel...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m30\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: scrape_channel() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "async def run_scraping():\n",
    "    async with TelegramClient('session', api_id, api_hash) as client:\n",
    "        if not await client.is_user_authorized():\n",
    "            await client.send_code_request(phone)\n",
    "            code = input(\"Enter the code you received: \")\n",
    "            await client.sign_in(phone, code)\n",
    "\n",
    "        for channel in CHANNELS:\n",
    "            await scrape_channel(client, channel)\n",
    "            logger.info(f\"Sleeping 30 seconds before next channel...\")\n",
    "            await asyncio.sleep(30)\n",
    "\n",
    "# Trigger the scraping\n",
    "await run_scraping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd71444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
